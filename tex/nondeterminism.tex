%% tex/nondeterminism.tex
%% Copyright 2019 Andrea Berlingieri
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Andrea Berlingieri.
%
% This work consists of all files listed in manifest.txt
\chapter{Complessita' non deterministica}

\section{Macchine di Turing non deterministiche}

Vediamo un altro modello di calcolo interessante, quello delle Macchine di Turing non
deterministiche.

Una MdT non deterministica e' definita in modo analogo alla versione deterministica, con la sola
differenza che la funzione di transizione $\delta$ e' multivalore:
\begin{equation*}
    \delta \subseteq Q \times \Sigma^{k} \times Q \times (\Sigma \times \set{L,R}^{k})^{k}
\end{equation*}

In altri termini nella MdTN invece di avere una sola quintupla per ogni coppia stato-carattere ne
abbiamo un insieme finito. In un certo senso e' come se avessimo un programma che, invece di avere
una singola istruzione con cui continuare, ha un insieme finito di istruzioni tra cui scegliere per
proseguire la sua computazione.

E' semplice da definire formalmente, basta modificare la definizione della macchina deterministica.
La macchina deterministica e' in un certo senso piu' difficile da definire formalmente rispetto alla
versione non deterministica, dato che la si puo' definire ponendo dei vincoli alla definizione di
quest'ultima.

La macchina deterministica rappresenta un caso particolare della macchina non deterministica dove la
scelta della quintupla e' univoca. Se qualcosa e' calcolabile da una macchina deterministica lo e'
anche da una non deterministica. Di conseguenza le classi deterministiche sono contenute nelle
corripondenti classi non determistiche. Ad esempio, $\PClass \in \NPClass$, $\PSPACE \in \NPSPACE$,
etc.

Definire la MdTN e' semplice. E' piu' complicato definire cosa calcola la MdTN. In una MdTN e'
facile capire che ci sono piu' computazioni possibili. Quale sia pero' il risultato calcolato dalla
macchina non e' ovvio.

Noi ci restringiamo a considerare solamente macchine decisionali, ovvero che rispondono si'/no.
Queste ci sono sufficienti perche' siamo interessati a riconoscere linguaggi. Le nostre macchine
terminano con risposta booleana.

Quando possiamo affermare che una stringa e' accettata da una MdTN? Abbiamo due criteri. Una stringa
puo' essere accettata dalla MdTN se, qualunque computazione della macchina venga fatta, la stringa
viene sempre accettata, oppure puo' essere accettata se esiste una computazione che accetta la
stringa. A noi interessa la seconda definizione, quella della ``macchina fortunata'': ogni volta che
abbiamo una scelta la nostra macchina fa quella giusta.

%Se esiste una computazione della MdTN che porta al riconoscimento la stringa e' considerata
%riconosciuta. // Ripetizione

La computazione della macchina puo' essere rappresentata da un grafo.

\begin{figure}[h]
    \begin{center}
        \includegraphics{./img/nondeterminism/MdTN.pdf}    
        \caption{Grafo delle computazioni di una MdTN}
    \end{center}
\end{figure}

Il grafo e' diretto non necessariamente aciclico. Il numero di scelte e' finito e definito dalla
macchina (dal programma), che e' finita. Il grafo non e' neanche necessariamente finito, dato che
possono esistere computazioni che non terminano non cicliche.

Ci porremo piu' avanti il problema di simulare la MdTN, e qui ci tornera' utile questo grafo, detto
grafo delle computazioni.

Alcuni cammini nel grafo portano a stati finali accettanti, altri no, altri possono andare avanti
indefinitamente. A noi basta che esista un cammino che porti ad una configurazione di accettazione
per riconoscere una stringa. 

%La nostra definizione di accettazione ci permettera' di avere delle relazioni con l'esistenza di un
%certificato.

Consideriamo $\SAT$. Come funzionerebbe la MdTN per $\SAT$? Noi dobbiamo prendere una formula
proposizionale e decidere se questa e' soddisfacibile. La nostra macchina comincia a leggere la
formula e trova come prima variabile proposizionale, ad esempio, $A$. $A$ e' vera o falsa? La
macchina ``tira una moneta'' e decide il valore di verita' di $A$. Dopodiche' la macchina va avanti.
Questo processo continua fino alla fine della formula. Se la formula e' soddisfacibile esiste almeno
una computazione fortunata che indovinera' l'assegnazione giusta di valori di verita' alle variabili
proposizionali.

Alla macchina non deterministica basta una scansione lineare della formula, e quindi riesce a
risolvere $\SAT$ in tempo lineare, a patto di prendere la strada giusta. $\SAT$ e' risolvibile in
tempo polinomiale non deterministico da una MdTN. Questa sara' anche il modo in cui definiremo la
classe $\NPClass$.

\section{Complessita' non deterministica}

Dobbiamo definire quali sono il tempo e lo spazio consumati dalla MdTN durante una computazione. Se
la macchina accetta l'input esiste una computazione accettante. Se la risorsa che consideriamo e' il
tempo noi prendiamo il tempo della computazione accettante piu' corta. In termini del grafo delle
computazioni prendiamo il piu' corto cammino accettante della MdTN e la lunghezza di quel cammino e'
il numero di passi richiesto per riconoscere una stringa $x$. Questo numero rappresenta quindi il
tempo richiesto dalla macchina. Indichiamo il tempo richiesto dalla MdTN $M$ su input $x$ con
$\textit{time}_{M}(x)$.

Analogamente per lo spazio prendiamo lo spazio minimo tra gli spazi richiesti dalle computazioni
accettanti. Tuttavia bisogna fare attenzione al come calcoliamo lo spazio richiesto da una
computazione. Questo corrisponde al massimo spazio usato in una configurazione della computazione.
Dobbiamo considerare il ``minimo dei massimi''. Indichiamo lo spazio richiesto dalla MdTN $M$ su
input $x$ con $\textit{space}_{M}(x)$.

Le funzioni $t_{M}$ e $s_{M}$ sono definite identicamente a come lo erano nel caso deterministico, a
patto di usare le nozioni di $\textit{time}$ e $\textit{space}$ appena definite. Un discorso analogo
di applica alle definizioni di $\NTIME(f)$ e $\NSPACE(f)$.

Possiamo definire le classi $\NPClass$, $\NEXP$, $\NLOGSPACE$ e $\NPSPACE$ in maniera identica a
come abbiamo definito le corrispondenti classi deterministiche, avendo cura di usare $\NTIME$ al
posto di $\DTIME$ e analogamente per lo spazio.

Possiamo formalizzare quanto detto prima sulla relazione tra macchine di Turing deterministiche e
non deterministiche con il seguente teorema.
\begin{thm}
    Per ogni $f: \Nat \to \Nat$
    \begin{equation*}
        \DTIME(f) \subseteq \NTIME(f) \land \DSPACE(f) \subseteq \NSPACE(f)
    \end{equation*}
\end{thm}
La dimostrazione e' ovvia essendo la macchina di Turing determinstica un caso particolare della
macchina non deterministica.

%(Abbiamo saltato la riduzione dei nastri)

\section{Simulazione del non determinismo}

Vogliamo stabilire delle relazioni tra la MdTN e la corrispondente macchina deterministica. Per
stabilire queste relazioni una tecnica che risulta utile e' pensare in termini di simulazione.
Siamo quindi interessati a teoremi che riguardano la simulazione del nondeterminismo.

Immaginiamo di avere una macchina non deterministica che riconosce un linguaggio con una certa
complessita' e immaginiamo di simularla con una macchina deterministica. Se riusciamo a determinare
la complessita' della simulazione rispetto alla complessita' della macchina di partenza riusciamo a
dire qualcosa sulla complessita' del riconoscimento del linguaggio in modo deterministico.

C'e' un modo interessante di vedere la simulazione della MdTN: consideriamo il grafo delle
computazioni di una MdTN. Per simulare la macchina in modo deterministico ci basta trovare un
algoritmo deterministico di visita dei cammini del grafo. Dobbiamo fare un'esplorazione completa,
dato che possono esistere in generale cammini di riconoscimento migliori di uno gia' trovato.
Dobbiamo fare una qualche visita astuta per effettuare la simulazione.

%Slide 89

In generale quando vogliamo stabilire delle relazioni tra classi deterministiche e classi non
deterministiche usiamo classi di risorse diverse. Ad esempio, avendo un bound di tempo alla
complessita' della MdTN diciamo qualcosa riguardo alla complessita' in spazio della simulazione
deterministica. Il primo teorema che vediamo mostra questo.

\subsection{Simulazione di una macchina non deterministica con un bound al tempo}

Supponiamo di conoscere la complessita' $O(f)$ in tempo della macchina non deterministica e ci
chiediamo quale sia la complessita' in spazio della simulazione deterministica, cercando di
minimizzare l'occupazione di memoria.

Quello che dobbiamo fare e' occupare il minor spazio possibile durante la nostra visita del grafo
delle computazioni. La visita in ampiezza non e' la migliore scelta in questo caso, dato che in
generale potremmo avere una frontiera attiva dei nodi da visitare molto ampia che non ci e'
necessaria.

Abbiamo che la MdTN lavora in $\NTIME(f)$. Abbiamo che $f$ rappresenta la lunghezza massima dei
cammini da esplorare, dato che sappiamo che nostra macchina non deterministica riconosce il nostro
linguaggio in tempo $O(f)$. Rispetto a questa lunghezza dei cammini il numero di nodi che possiamo
avere cresce in generale esponenzialmente: se avessimo, ad esempio, per ogni nodo, una scelta
binaria avremmo $2^{n}$ nodi.

Consideriamo una visita in profondita'. Esploriamo il primo cammino, con lunghezza $O(f(|x|))$.
Quante configurazioni incontriamo? $O(f(|x|))$. Possiamo dire qualcosa sulla dimensione di queste
configurazioni? 

Abbiamo che anche per la MdTN il tempo fa da bound al tempo. Per ogni configurazione l'aspetto che
influisce di piu' sull'occupazione di spazio e' la dimensione dei nastri. I nastri crescono, al
massimo, in modo lineare rispetto al tempo. La dimensione dei nastri e' bound da $O(f(|x|))$. Per
memorizzare la catena della configurazioni ci serve $O((f(|x|))^{2})$ spazio. 

Questo e' lo spazio richiesto per la visita di un ramo del grafo. Tuttavia il ramo che stiamo
visitando potrebbe essere un ramo di fallimento, oppure un ramo che diverge. Nel caso fossimo in uno
di questi due casi, una volta raggiunta una configurazione di fallimento o una volta che abbiamo
raggiunto il bound in tempo della MdTN senza accettare possiamo tornare indietro lungo il ramo alla
prima configurazione dove ci e' ancora possibile fare una scelta e effettuarne una diversa.
Procediamo quindi per backtracking. In ogni caso l'occupazione di tutti i cammini che esploriamo ha
gli stessi upper bound dati per il primo cammino.

Con una simulazione di questo tipo lo spazio richiesto dalla simulazione deterministica della MdTN
e' dell'ordine di $O(f^{2})$.

Possiamo pero' fare di meglio. Perche'?

In generale come facciamo a risparmiare spazio? Possiamo rendere implicite le rappresentazioni
esplicite dei dati, attraverso una descrizione compatta che prendera' tempo al momento
dell'esecuzione ma ci permettera' di risparmiare spazio. Al costo del tempo risparmiamo spazio.
Tutto cio' che ci e' oneroso dal punto di vista della memoria lo rendiamo implicito attraverso una
sintesi compatta (ad esempio una compressione). Quando, in fase di esecuzione, avremo bisogno del
dato ci bastera' spendere un po' di tempo per estrarlo dalla sua descrizione.

Abbiamo una tecnica analoga per risparmiare tempo a costo dello spazio. Pensiamo ad esempio alla
programmazione dinamica con memoization. Manteniamo una tabela per memorizzare le soluzioni dei
sottoproblemi. Quando ci serve una soluzione ad un sottoproblema possiamo guardare la tabella e, nel
caso il sottoproblema sia gia' stato risolto, ottenere subito il risultato richiesto. Se questo non
e' il caso risolviamo il sottoproblema e memorizziamo la soluzione in tabella per usi futuri.

Tempo e spazio sono due risorse ``complementari''. Non si puo', allo stesso tempo, ottimizzare il
tempo e lo spazio. Ottimizzare in tempo richiede spendere in spazio e viceversa.  Di solito siamo
portati a pensare a ottimizzazioni del tempo, senza considerare lo spazio.

Quello che occupa piu' spazio nella nostra visita dei cammini e' la memorizzazione esplicita della
catena di configurazioni. Possiamo dare una descrizione del cammino che prendiamo nel grafo molto
piu' compatta, ad esempio come sequenza di scelte fatte dalla configurazione iniziale. Possiamo
etichettare ogni scelta nel cammino con un numero e salvarci le etichette del nostro cammino.
L'unica informazione che ci serve per definire il cammino e' la sequenza delle scelte prese. Nel
caso dovessimo fare backtracking possiamo ripercorrere tutte le scelte del cammino corrente fino
alla scelta da rivedere e cambiare scelta. Considerando tutte le possibili scelte avremo considerato
tutti i possibili cammini del grafo.

Quanto ci costa memorizzare questa sequenza di scelte? L'unica configurazione che teniamo attiva e'
quella finale, che e' bound da $O(f(|x|))$ per il teorema tempo spazio. Le scelte sono in un range
finito fissato dalla macchina.

In definitiva ci serviranno $c\cdot O(f(|x|))$ per memorizzare le scelte e $O(f(|x|))$ per la
configurazione finale del cammino. L'ordine dell'occupazione di spazio della simulazione fatta in
questo modo e' quindi $O(f(|x|))$. Riusciamo a fare la simulazione della MdTN in spazio $O(f(x))$.

\begin{thm}\label{thm:ntimedspace}
    Per ogni $f:\Nat \to \Nat$ costruibile in spazio maggiore o uguale all'identita'
    \begin{equation*}
        \NTIME(f) \subseteq \DSPACE(f)
    \end{equation*}
\end{thm}

Possiamo vedere la simulazione in un modo piu' operazionale. Dato $x$ inizializziamo due nastri di
dimensione $f(|x|)$. In un nastro memorizziamo il tape e in un altro le scelte. All'inizio
simuleremo la computazione dove la scelta che facciamo e' sempre la prima. Sul nastro del tape
simuliamo la computazione della MdTN. A questo punto arriviamo in fondo in vari modi: o terminiamo
il tempo, o cerchiamo di sforare lo spazio, o ci arrestiamo con riconoscimento, o ci arrestiamo con
fallimento. In quest'ultimo caso andiamo a cambiare l'ultima scelta per fare backtracking e
rifacciamo la computazione. L'occupazione di spazio rimane dell'ordine $O(f)$. Dovremmo memorizzare
anche un timer per non sforare in tempo, ma questo ha occupazione logaritmica nel valore di $f$, di
conseguenza l'occupazione di spazio non peggiora.

\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.7]{./img/nondeterminism/Simulation.pdf}
        \caption{Simulazione deterministica di una MdTN con memoriazzazione delle scelte}
    \end{center}
\end{figure}

% TODO change all explicit references to "teorema tempo spazio" with a \ref to the right theorem
La simulazione del nondeterminismo non richiede un grande utilizzo di spazio. Il teorema
\ref{thm:ntimedspace} generalizza il teorema tempo spazio: non solo $\DTIME(f)$ e' contenuto in
$\DSPACE(f)$, ma anche $\NTIME(f)$. Dal teorema e dall'inclusione $\DTIME(f) \subseteq \NTIME(f)$
deriva il teorema tempo spazio.

\subsection{Simulazione di una macchina non deterministica con un bound allo spazio}

Vediamo ora cosa possiamo dire della complessita' in tempo della simulazione di una MdTN che lavora
con una data complessita' in spazio.

Sia $M$ una MdTN che riconosce un linguaggio $\Lang \in \NSPACE(f)$ e consideriamo il suo grafo di
raggiungibilita'. Possiamo fare un'ipotesi aggiuntiva su questo grafo e dire che esiste un'unica
configurazione finale di riconoscimento. Cio' e' diverso dall'affermare che abbiamo un solo stato
finale di riconoscimento. Possiamo fare questa ipotesi perche' in generale possiamo ``canonizzare''
tutte le configurazioni finali di una MdTN ``ripulendo'' i nastri, e ottenere una macchina con la
stessa complessita' in spazio con un'unica configurazione finale. Questa operazione di
canonicalizzazione degli stati finali richiedera' sicuramente del tempo ma non dello spazio
aggiuntivo.

\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.7]{./img/nondeterminism/Canonicalization.pdf}
        \caption{Canonicalizzazione di una MdTN $M$.}
    \end{center}
\end{figure}

Sotto questa ipotesi possiamo vedere la simulazione deterministica di $M$ come la ricerca di un
cammino dalla configurazione iniziale all'unica configurazione finale accettante. La complessita' di
questa operazione sara' proporzionale alla dimensione del grafo delle computazioni di $M$.

Possiamo dare un upper bound alla dimensione del grafo? Si'. Cerchiamo di capire quanti sono i nodi
di questo grafo. Gli archi saranno di ordine quadrato rispetto a questa quantita'. I nodi sono le
possibili configurazioni finite diverse possibili. Abbiamo che la dimensione dei nastri e' $O(f)$.
Sappiamo quante sono le configurazioni possibili dato un bound allo spazio: saranno una quantita' di
ordine esponenziale in $f$. Abbiamo quindi che la dimensione del grafo sara' $O(2^{cf})$.

\begin{thm}\label{thm:nspacedtime}
    Per ogni $f:\Nat \to \Nat$ costruibile in spazio maggiore esiste $c \in \Nat$ tale che
    \begin{equation*}
        \NSPACE(f) \subseteq \DTIME(2^{c(\log + f)})
    \end{equation*}
\end{thm}

Il $\log$ nell'esponenziale ci indica, come sempre, che richiediamo che $f$ sia almeno $\geq
\log(n)$. Questo perche' consideriamo complessita' in tempo almeno lineari.

Anche in questo caso abbiamo una generalizzazione del teorema tempo spazio. Questa generalizzazione
e' stretta se supponiamo che $\DSPACE(f) \subset \NSPACE(f)$. Questo, al solito, si congettura ma
non e' ancora stato dimostrato. Abbiamo che $\DSPACE(f) \subseteq \NSPACE(f)$, da cui $\DSPACE(f)
\subseteq \DTIME(2^{c(log + f)})$.

Possiamo dire che i teoremi tempo spazio valgono se immaginiamo che dalla parte sinistra delle
inclusioni abbiamo una macchina non deterministica.

Possiamo ora concludere qualcosa riguardo all'utilizzo di risorse dello stesso tipo nella
simulazione di una MdTN.

Supponiamo di avere una MdTN che lavora con complessita' in $\NTIME(f)$. Per il teorema
\ref{thm:ntimedspace} abbiamo che $\NTIME(f) \subseteq \DSPACE(f)$. Per il teorema tempo spazio
$\DSPACE(f) \subseteq \DTIME(2^{cf})$, per un $c$ opportuno. Di conseguenza $\NTIME(f) \subseteq
\DTIME(2^{cf})$. Potrebbe andare meglio per casi specifici, ma l'upper bound dato e' sempre valido.
Questo risultato non e' tanto sorprendente, se consideriamo un tipico grafo delle computazioni di
una MdTN.

Cosa possiamo dire per lo spazio? Abbiamo sicuramente che $\NSPACE(f) \subseteq \DTIME(2^{cf})$, per
un opportuno $c$. Per il teorema tempo spazio abbiamo che $\DTIME(2^{cf}) \subseteq
\DSPACE(2^{cf})$, da cui $\NSPACE(f) \subseteq \DSPACE(2^{cf})$. Questo risultato e' meno intuitivo,
dato che lo spazio e' una risora riutilizzabile. Il tempo, invece, non lo e'. Potremmo usare lo
spazio gia' usato per una computazione per provarne un'altra. Non e' ovvio che si possa fare meglio,
ma si puo' ed e' dimostrabile. Inoltre il miglioramento e' molto significativo.

\subsection{Teorema di Savitch}

\begin{thm}
    \textbf{(Teorema di Savitch).} Sia $f:\Nat \to \Nat$ una funzione costruibile in spazio e tale
    che $\log \in O(f)$. Allora
    \begin{equation*}
        \NSPACE(f) \subseteq \DSPACE(f^{2})
    \end{equation*}
\end{thm}

Simulare in modo deterministico una computazione non deterministica che richiede spazio $O(f)$ e'
fattibile in spazio $O(f^{2})$.

E' un teorema importante perche' ha un corollario molto rilevante. Una simulazione deterministica di
una MdTN ha un overhead esponenziale in tempo, ma non in spazio. Abbiamo un overhead quadratico.

L'idea e' sempre quella di fare una visita del grafo. Supponiamo di essere sotto l'ipotesi di
unicita' della configurazione finale accettante. Siamo alla ricerca di un cammino che vada dalla
configurazione iniziale a quella finale cercando di occupare il minor spazio possibile. Solitamente
si adoperano due algoritmi per questa problematica: DFS e BFS. Abbiamo gia analizzato la loro
complessita' in tempo, ci chiediamo quale sia la loro complessita' in spazio.

Consideriamo DFS. La massima profondita' di una visita e' uguale al numero dei nodi, visto che
consideriamo cammini aciclici. Possiamo supporre di avere una descrizione compatta di un cammino, ma
sara' sempre lineare nel numero dei nodi in dimensione. Questo discorso si applica anche a BFS. La
frontiera che possiamo ottenere, nel caso pessimo, puo' avere dimensione pari al numero di nodi del
grafo. Questi due algoritmi hanno un'occupazione di memoria almeno lineare.

Esiste pero' un algoritmo per questa problematica concettualmente semplice ma con un'occupazione di
memoria sorprendentemente bassa: $O(\log^{2}(n))$, dove $n$ e' il numero dei nodi. Questo e' lo
spazio aggiuntivo richiesto, ignorando lo spazio richiesto dall'input.

L'algoritmo utilizza una funzione ricorsiva che possiamo chiamare $\REACH$. $\REACH$ prende in input
due nodi $u$ e $v$ e un parametro $i$. Supponiamo che i nodi siano stati numerati e che $u$ e $v$
siano quindi numeri. Il problema che $\REACH$ risolve e' determinare se esiste un cammino da $u$ a
$v$ di lunghezza $\leq 2^{i}$.

L'idea e' quella di fare una sorta di divide-et-impera. Abbiamo $u$, $v$ e cerchiamo un cammino di
lungheza $\leq 2^{i}$. Se questo esiste possiamo spezzarlo in due cammini di lunghezza $\leq
2^{i-1}$. In questo caso esiste anche un nodo $x$ ed un cammino di lunghezza $\leq 2^{i-1}$ da $u$ a
$x$ e un cammino analogo da $x$ a $v$. Tuttavia non sappiamo quale nodo sia l'$x$ che cerchiamo; di
conseguenza per trovarlo facciamo una ricerca esaustiva su tutti i possibili $x$.

\begin{figure}[h]
    \begin{center}
        \includegraphics{./img/nondeterminism/SavitchAlgorithm.pdf}
        \caption{Possiamo dividere la ricerca di un cammino di lunghezza $\leq 2^{i}$ nella ricerca
        di due cammini di lunghezza $\leq 2^{i-1}$, utilizzando lo stesso algoritmo.}
    \end{center}
\end{figure}

Lo pseudocodice e' il seguente:

\RestyleAlgo{ruled}
\begin{algorithm}
%    \SetNlSty{texttt}{(}{)}
    \caption{\REACH(\textsc{Graph} $G$,\textsc{Node} $u$,\textsc{Node} $v$, \textbf{integer} $i$)}
    \If {$i = 0$}
    {
        \Return{$u = v \lor (u,v) \in G.V$}
    }
    \Else
    {
        $\textbf{boolean } res \gets \textbf{false}$

        \ForEach{$x \in G.V$}
        {
            $res \gets res \lor (\REACH(G,u,x,i-1) \land \REACH(G,x,v,i-1)$
        }

        \Return{$res$}
    }
\end{algorithm}

Questo algoritmo e' noto come algoritmo di Savitch.

La chiamata iniziale la faremo con un upper bound alla lunghezza massima. Poiche' la lunghezza
massima di un cammino aciclico in un grafo e' $n$, come valore iniziale per $i$ useremo $\log(n)$:
infatti $2^{\log(n)} = n$.

Dicutiamo la complessita' in spazio di questo algoritmo. Supponiamo di implementare le chiamate
ricorsive dell'algoritmo mediante uno stack di record di attivazione. Cio' che influisce
sull'occuazione di spazio e' il numero massimo di chiamate annidate che possiamo avere e la
dimensione massima dei record di attivazione. Qual e' il numero massimo di chiamate annidate? $i$,
dato che ad ogni chiamata l'input decresce. Abbiamo che $i \leq \log(n)$.

Possiamo dare un upper bound anche alla dimensione dei record di attivazione. Nei record di
attivazione abbiamo, in genere, l'input, l'output e le variabili locali. Le variabili di questa
procedura sono, ad esempio, \textit{res} e $x$. Qual'e' la dimensione di queste variabili? I nodi
sono dei numeri e la risposta e' un booleano. Per memorizzare i nodi ci basta $O(\log(n))$, mentre
per memorizzare la risposta ci e' sufficiente uno spazio costante. Avremo un numero costante $k$ di
variabili locali, ma questo non influisce sulla complessita'.

Di conseguenza la dimensione richiesta per capire se due nodi sono raggiungibili e' dato da $i\cdot
k\log(n) \leq k\log^{2}(n)$, ovvero $O(\log^{2}(n))$. Allo stato dell'arte non si riesce a fare di
meglio a livello di occupazione di spazio.

Qual'e' la complessita' in tempo di questa procedura? Ricordiamo che abbiamo un trade-off quando
ottimizziamo lo spazio: questa operazione ci costa in tempo. Scriviamo la relazione di ricorrenza:
il tempo $t$ richiesto al passo $i$ e' dato da:
\begin{equation*}
    t^{i} = 
    \begin{cases}
        \case{d}{se $i = 0$}\\
        \case{N\cdot 2t^{i-1}}{altrimenti}\\
    \end{cases}
\end{equation*}

Il numero di chiamate e' $i \leq \log(N)$. Abbiamo quindi una complessita' $O((N\cdot 2)^{\log(N)})
= O(N^{\log(N)}2^{\log(N)}) = O(N\cdot N^{log(N)}) = O(N^{\log(N)+1})$. Potevamo ottenere un bound
simile con il teorema tempo spazio.

E' un problema aperto della teoria della complessita' riuscire a trovare, se esiste, un algoritmo
che stia ``a meta''' tra questo algoritmo, che ottimizzza lo spazio, e un tipico algoritmo di visita
che ottimizza il tempo.

Tornando alla dimostrazione del teorema di Savitch, sappiamo che riusciamo a fare la ricerca di un
cammino dalla configurazione iniziale a quella finale con uno spazio limitato. Qual e' la dimensione
del grafo? Se $f$ e' il bound asintotico allo spazio abbiamo un numero di configurazioni
$O(2^{cf})$, per un $c$ opportuno. Con questa dimensione del grafo e utilizzando l'algoritmo di
Savitch abbiamo una complessita' $\log^{2}(2^{cf}) = (cf)^{2}$, ovvero $O(f^{2})$.

% TODO rivedi registrazione su questo punto
Questa complessita' e' tale se nell'occupazione di spazio consideriamo solo quello aggiuntivo
richiesto per la computazione, ignorando quello richiesto per memorizzare l'input. Possiamo fare
questa ipotesi perche' possiamo lavorare con il grafo in maniera implicita. L'unico momento in cui
ci serve esplicitamente il grafo e' nel caso base dell'algoritmo. Abbiamo una configurazione
$c_{u}$, una configurazione $c_{v}$ e ci chiediamo se si puo' andare, in un passo, da $c_{u}$ a
$c_{v}$. Dal punto di vista dell'occupazione in spazio questo richiede uno spazio uguale al massimo
tra quelli richiesti da $c_{u}$ e da $c_{v}$. L'importante e' fissare $M$, di dimensione costante
che dipende dal programma.

Cosa ci dice questo teorema su $\NPSPACE$? Supponiamo di avere un polinomio, ad esempio $n^{2}$.
Supponiamo di voler riconoscere un linguaggio $\Lang \in \NSPACE(n^{2})$. Per il teorema di Savitch
abbiamo che lo stesso linguaggio sta in $\DSPACE(n^{4})$. In generale il quadrato di un polinomio e'
ancora un polinomio. Di conseguenza abbiamo che $\NPSPACE \subseteq \PSPACE$. Poiche' le macchine
deterministiche sono un caso particolare di macchine non deterministiche, come ulteriore conseguenza
abbiamo che $\NPSPACE = \PSPACE$.

Questo e' l'equivalente, a livello dello spazio, del problema $\PClass$ vs $\NPClass$. Se avessimo
un risultato simile per il tempo, ad esempio $\NTIME(f) \subseteq \DTIME(f^{20})$, potremmo
concludere $\PClass = \NPClass$. Tuttavia un risultato del genere probabilmente non e' dimostrabile.

Il motivo per cui l'occupazione di spazio dell'algoritmo di Savitch e' compatta e' che non
memorizziamo nulla delle computazioni gia' fatte, mentre la complessita' in tempo rimane elevata
dato che per ogni coppia di nodi $u$ e $v$ del grafo sara' ripetuta varie volta l'interrogazione
``il nodo $u$ e' raggiungibile dal nodo $v$?''.

Non e' possibile risparmiare il tempo di queste computazioni memorizzando, ad esempio, i risultati
delle varie interrogazioni in una tabella. Questo perche' il numero dei nodi e' esponenziale nella
complessita' in spazio. La dimensione di questa tabella sarebbe anch'essa esponenziale e non
riusciremmo a lavorare in uno spazio quadratico in $f$. Come sempre se vogliamo risparmiare in
spazio dobbiamo essere disposti a ``spendere'' in tempo, e viceversa.

%Slide 103
\subsection{Gerarchie di complessita'}

Possiamo, dati i risultati sulle computazioni non deterministiche, rappresentare le relazioni di
inclusioni mediante la figura \ref{nondeterminism:img:complexity_hierarchy}:

\begin{figure}[h]
    \begin{center}
        \includegraphics{./img/nondeterminism/Hierarchies.pdf}
        \caption{Rappresentazione delle relazioni di inclusioni note tra alcune classi di
        complessita'.}
        \label{nondeterminism:img:complexity_hierarchy}
    \end{center}
\end{figure}

Il significato degli archi e dei segni di disuguaglianza e' lo stesso che abbiamo dato per la figura
\ref{timespacehierarchies:img:detclassesrelations}.

Abbiamo che $\LOGSPACE \subseteq \NLOGSPACE$ perche' le macchine deterministiche sono un caso
particolare di quelle non deterministiche. Abbiamo inoltre che $\NLOGSPACE \subseteq \PClass$ per il
teorema \ref{thm:nspacedtime}. Sappiamo che $\PClass \subset \EXP$ per il teorema della gerarchia in
tempo, e analogamente abbiamo che $\NPClass \subset \NEXP$. Sappiamo che $\NPClass \subseteq \PSPACE$
per il teorema \ref{thm:nspacedtime} e sappiamo che $\PSPACE = \NPSPACE$ per il teorema di Savitch.
Sappiamo infine che $\PSPACE \subset \EXPSPACE$ per il teorema della gerarchia e che $\NEXP
\subseteq \EXPSPACE$ per il teorema \ref{thm:nspacedtime}.

L'inclusione stretta tra $\NPClass$ e $\NEXP$ non e' ovvia. In effetti si puo' dimostrare che i
teoremi della gerarchia sono generalizzabili al caso non deterministico, e questo giustifica questa
relazione tra le due classi.


\section{La classe $\NPClass$}

%Slide 105
Vediamo ora due argomenti importanti concentrando la nostra attenzione su una classe di complessita'
molto interessante: $\NPClass$. I due argomenti che trattiamo sono il teorema della proiezione e la
nozione di riducibilita'.

\subsection{Teorema della proiezione}

Il teorema della proiezione e' importante perche' mette in relazione le due visioni della classe
$\NPClass$: una, che la definisce, e' quella di insieme dei linguaggi riconoscibili da una macchina
non deterministica, e l'altra, interessante a livello pratico, e' quella di insieme dei problemi per
cui esistono algoritmi di verifica della soluzione che operano in tempo polinomiale.

\begin{thm}
    \textbf{(Teorema della proiezione).} Dato un linguaggio $A \subseteq \Sigma^{*}$, $A \in
    \NPClass$ se e solo se esiste un linguaggio $B \in \PClass$ e un polinomio $p$ tale che per ogni
    $x \in \Sigma^{*}$
    \begin{equation*}
        x \in A \iff \exists y, |y| \leq p(|x|) \land \pair{x}{y} \in B
    \end{equation*}
\end{thm}

$y$ e' un certificato che dipende da $x$. E' un'informazione aggiuntiva rispetto ad $x$ che ci
permette di fare una verifica veloce. E' una sorta di ``prova'' che $x$ appartiene in effetti al
linguaggio $A$. L'utilita' di $B$ sta nel fatto che ci permette di verificare in tempo polinomiale
l'autenticita' del certificato per $x$.

Che cosa sia il cerficicato non e' ben definito: dipende dal problema e sta a noi definire cosa sia
un buon cerificato. Dato che noi consideriamo solo problemi decisionali il certificato puo' essere
qualunque informazione che ci permetta di verificare che la risposta sia ``Si'''.

Chiediamo inoltre che la dimensione del certificato non cresca esponenzialmente. Il motivo e' che
input grandi ci danno complessita' basse che sono tuttavia fittizie, un po' come accadeva per il
padding.

Ad esempio per il problema della tautologia abbiamo un algoritmo lineare nella dimensione di una
tabella di verita' che verifica se la tabella e' ben formata, e quindi se una formula data e'
tautologica. Tuttavia questa tabella ha dimensione esponenziale. L'algoritmo risulta efficiente se
confrontato con la dimensione della tabella, ma risulta pessimo se confrontato con la dimensione del
nostro input, ovvero la formula di partenza. Di conseguenza non si tratta di un buon certificato per
noi.

\begin{proof}

    Sia $A \subseteq \Sigma^{*}$, $A \in \NPClass$ e sia $x$ una stringa in $A$. Abbiamo che $A \in
    \NPClass$ sse esiste una MdTN $M$ che riconosce $A$. Che certificato possiamo dare per $x$?
    Come certificato possiamo prendere la sequenza delle scelte prese da $M$ in una computazione che
    riconosce $x$, insieme a $\code{M}$. Quanto e' grande questa sequenza? E' polinomiale in $|x|$,
    essendo $A \in \NPClass$. Esiste quindi un cammino accettante polinomiale nel numero di passi.
    Il codice di $M$ e' costante nella sua dimensione e non influisce a livello della complessita'.
    Sia $B$ il linguaggio delle coppie $x$-certificato. Dato $x$ ed il suo certificato una macchina
    deterministica $M'$ che riconosce il linguaggio $B$ effettua una simulazione di $M$ usando le scelte
    fornite. Se la configurazione finale della simulazione di $M$ e' accettante la machina $M'$
    accetta la coppia $x$-certificato; in caso contrario rifiuta. E' facile verificare il secondo $\iff$
    dell'enunciato del teorema data questa definizione di $M'$ e $B$. Inoltre abbiamo che $B \in
    \PClass$, dato che l'estrazione del certificato dalla coppia e' un'operazione con complessita'
    lineare rispetto alla dimensione di questa e la simulazione di $M$ richiede un numero di passi
    polinomiale in $|x|$.

    Viceversa supponiamo ora di avere $B \in \PClass$. Vogliamo dimostrare che se prendiamo un
    polinomio $p$ e facciamo la proiezione esistenziale bound da $p$ abbiamo che il linguaggio
    ottenuto in questo modo sta in $\NPClass$. In particolare vogliamo dimostrare che il linguaggio
    \begin{equation*}
        A = \set{x \mid \exists y, y \leq p(|x|) \land \pair{x}{y} \in B}
    \end{equation*}
    fa parte di $\NPClass$.

    Per mostrare cio' esibiamo una MdTN $M$ che ci permetta di riconoscere $A$. $M$ funziona nel
    seguente modo: dato $x$ genera tutti i certificati $y$ di dimensione minore o uguale a $p(|x|)$
    e testa l'appartenenza di $\pair{x}{y}$ a $B$ in tempo polinomiale per tutti. Se uno di questi
    certificati risulta valido $M$ accetta $x$, altrimenti rifiuta. La quantita' di certificati da
    testare e' esponenziale, dato che il numero di certificati diversi di lunghezza $p(|x|)$ e'
    $|\Sigma|^{p(|x|)}$. Sfruttando il fatto che la macchina deterministica e' ``fortunata''
    generiamo non deterministicamente il certificato corretto per $x$. $M$ riconosce quindi $x
    \in A$ in tempo polinomiale non deterministico.

\end{proof}

Non e' restrittivo supporre, come abbiamo fatto implicitamente, che $B$ sia un linguaggio sullo
stesso alfabeto $\Sigma$ di $A$.

\subsection{Riducibilita'}

%Slide 112

La nozione di riducibilita' che vediamo e' molto simile a quella della teoria della complessita'.

\begin{defn}
    Siano $A,B \in \Sigma^{*}$ due linguaggi. Diremo che $A$ e' riducibile in tempo polinomiale a
    $B$, $A \leq_{p} B$, se esiste $f \in \FP$ tale che per ogni $x \in \Sigma^{*}$, $x \in A \iff
    f(x) \in B$.
\end{defn}
Se al vincolo polinomiale alla complessita' di $f$ andiamo a sostituire un diverso vincolo sulla
complessita' in tempo o in spazio otteniamo una nozione di riducibilita' analoga a questa ma diversa
nel numero e nella natura delle riduzioni.

La nozione di riducibilita' e' many-to-one. Vogliamo che $f$ sia calcolabile in tempo polinomiale.
Nella definizione di riducibilita' dobbiamo fare attenzione ad un dettaglio tecnico.  Dire che $f
\in \PClass$ e' sbagliato perche' $f$ non e' un linguaggio, bensi' una funzione. Per questo motivo
introduciamo $\FP$ come l'insieme delle funzioni calcolabili in tempo polinomiale, ovvero delle $f$
per le quali esiste una MdT che calcola $f$ in tempo polinomiale.

Qualunque tipo di nozione di riducibilita' e' ragionevole. Piu' sono deboli i vincoli che poniamo
alla complessita' di $f$ piu' la nostra nozione di riduzione sara' lasca e maggiori saranno le
riduzioni possibili. Intuitivamente se disponiamo di un numero elevato di risorse e' piu' facile
ridurre un linguaggio ad un altro, mentre se le risorse disponibili sono limitate le riduzioni
possibili diminuiscono. Ad esempio una riducibilita' esponenziale permetterebbe di ridurre molti
problemi tra loro. Noi ci concentriamo unicamente sulla riducibilita' polinomiale in tempo. E'
generalmente la piu' interessante.

Le riducibilita' sono in genere dei preordini. Ricordiamo che un preordine e' una relazione binaria
riflessiva e transitiva. Per la riducibilita' polinomiale in tempo la proprieta' riflessiva e'
dimostrabile in maniera ovvia. Per la transitivita' supponiamo di avere $A,B,C$ con $A \leq_{p} B$
attraverso $f$ e $B \leq_{p} C$ attraverso $g$. Ci basta comporre $f$ e $g$ per ottenere $h$
calcolabile con complessita' polinomiale che riduce $A$ a $C$. Questa composizione ha complessita'
polinomiale perche' la composizione di polinomi e' ancora un polinomio. Questo vale anche per
$\leq_{L}$, la riducibilita' in $\LOGSPACE$.

%Slide 113

\begin{defn}
    Sia $\CClass$ una classe di linguaggi e sia $\leq$ un qualche preordine. Diremo che $\CClass$ e'
    chiusa rispetto a $\leq$ se
    \begin{equation*}
        A \leq B \land B \in \CClass \implies A \in \CClass
    \end{equation*}
\end{defn}

Si puo' dimostrare che che $\PClass$, $\NPClass$ e $\PSPACE$ sono chiuse rispetto alla riduzione
polinomiale.

Supponiamo infatti di avere due linguaggi $A$ e $B$, con $B \in \PClass$, e di voler riconoscere il
linguaggio $A$. Sia $x$ la stringa che vogliamo riconoscere. Se esiste una funzione di riduzione $f
\in \FP$ da $A$ a $B$ possiamo calcolare la riduzione $f(x)$ in tempo polinomiale.  Sappiamo che la
dimensione di $f(x)$ sara' polinomiale rispetto alla dimensione di $x$, dato che $f$ e' stata
calcolata in tempo polinomiale e lo spazio e' bound dal tempo. Inoltre verificare che $f(x) \in B$
richiede tempo polinomiale. Poiche' la composizione di polinomi rimane un polinomio questa procedura
di riconoscimento di $A$ ha complessita' polinomiale. Lo stesso discorso si applica se al posto di
$\PClass$ abbiamo $\NPClass$.

Una classe come $\LOGSPACE$ non e' chiusa rispetto alla riducibilita' in tempo polinomiale. E'
chiusa rispetto alla riducbilita' in spazio logaritmico. Supponiamo che $B \in \LOGSPACE$ e che $A
\leq_{p} B$. Questo non implica che $A \in \LOGSPACE$. Gia' il valore di $f(x)$ puo' avere
dimensione polinomiale, e lo spazio logaritmico non ci basta. Il problema e' che questa nozione di
riducibilita' e' troppo lasca per la classe che vogliamo studiare e ne serve una piu' precisa.

La classe $\PClass$ non e' chiusa rispetto alla riduzione esponenziale. Infatti possiamo ridurre un
qualsiasi problema $A$ in tempo esponenziale ad uno piu' semplice $B \in \PClass$. Questo non
implica che abbiamo un algoritmo per risolvere $A$ in tempo polinomiale e che quindi $A \in
\PClass$.

Vedremo che tutti i problemi non banali in $\PClass$ sono mutuamente riducibili con una riduzione
polinomiale. Inoltre tutti i problemi in $\EXP$ sono $\EXP$-completi. Infine esiste una riduzione
esponenziale da un problema in $\EXP$ ad uno in $\PClass$.

%Slide 114

\subsection{$\NPClass$-completezza e $\NPClass$-hardness}

La definizione di problema arduo e problema completo puo' essere data per qualsiasi classe di
complessita'. Noi siamo interessati a $\NPClass$.

\begin{defn}
    Sia $\CClass$ una classe di linguaggi e $\leq$ un preordine tra di essi. Sia $B$ un linguaggio.
    Abbiamo che
    \begin{itemize}
        \item $B$ e $\CClass$-arduo rispetto a $\leq$ se ogni $A \in \CClass$ e' riducibile a $B$;
        \item $B$ e $\CClass$-completo rispetto a $\leq$ se $B \in \CClass$ e $B$ e' $\CClass$-arduo;
    \end{itemize}
\end{defn}

Un problema $\CClass$-arduo e' il problema piu' complicato della classe. Questa nozione di
complicatezza pero' dipende dalla quantita' di risorse che diamo alla nozione di riducibilita.  Meno
risorse diamo alla funzione di riduzione, meno sono le riduzioni possibili, e piu' fini sono le
distinzioni tra classi, e analogamente con piu' risorse vale il contrario.

\begin{defn}
    Sia $B$ un linguaggio. Diciamo che $B$ e' $\NPClass$-hard se $\forall A \in \NPClass, A \leq_{p}
    B$. Diciamo che $B$ e' $\NPClass$-completo se $B$ e' $\NPClass$-hard e inoltre $B \in \NPClass$.
\end{defn}

I problemi $\NPClass$-completi sono quei problemi a cui tutti gli altri sono riducibili. Se avessimo
un modo efficiente per risolvere un problema $\NPClass$-completo $A$ sapremmo che, per ogni altro
problema in $\NPClass$, esisterebbe un algoritmo efficiente di soluzione che utilizza una riduzione
polinomiale dal problema da risolvere ad $A$ e l'algoritmo per $A$.

L'$\NPClass$-completezza e' interessante a livello pratico. Un problema che sappiamo essere
$\NPClass$-completo e' $\SAT$. Esistono algoritmi molto efficienti che possono risolvere $\SAT$ in
maniera efficiente nonostante la loro complessita' nel caso pessimo rimanga esponenziale. Si
utilizzano proprieta' di sottoclassi particolari di formule proposizionali che permettono di avere
algoritmi di soluzione generalmente efficienti. Non e' una cattiva idea risolvere un problema
trovando una riduzione polinomiale a $\SAT$ e usare un $\SAT$-solver, dato che $\SAT$ e' stato molto
investigato ed esistono algoritmi ed euristiche efficienti. Si potrebbe fare la stessa cosa
utilizzando altri problemi $\NPClass$-completi.

Non si sa se tutti i problemi in $\NPClass$ sono $\NPClass$-completi. Per $\PClass$ questa cosa
invece vale.  Se riusciamo a dimostrare che esiste un problema in $\NPClass$ non $\NPClass$-completo
abbiamo come conseguenza che
$\PClass \not= \NPClass$.

%Uguaglianza di Leibniz: $x = y \iff \forall P, P(x) \iff P(y)$. Due oggetti sono uguali se qualsiasi
%osservazione facciamo su di essi otteniamo lo stesso risultato. Se dimostriamo che c'e' qualche
%proprieta' che vale per un $x$ ma non per un $y$ abbiamo che $x \not= y$.

La questione $\PClass$ vs $\NPClass$, ovvero determinare se queste due classi coincidono o sono
diverse, e' uno dei Millenium Problems. C'e' in palio un premio di 1 milione di dollari per chi
fosse in grado di risolvere questo problema, o fare comunque passi importanti verso la risoluzione.
Si congettura che $\PClass \not= \NPClass$.

Una problematica ancora aperta e altrettanto interessante e' la dimostrazione che l'inclusione tra
$\PClass$ e $\PSPACE$ e' stretta. $\PSPACE$ e' una classe molto grande, che contiene anche
$\NPClass$, e molto distante da $\PClass$. Si congettura che l'inclusione sia stretta, ma non si e'
ancora riusciti a dimostrarlo. Un problema con questa dimostrazione e' legato al fatto che le due
classi sono definite da risorse diverse. Lavorare con risorse diverse a livello di complessita' e'
sempre delicato e non banale.

%Slide 116

Vediamo un esempio di problema $\NPClass$-completo

Dimostrare la completezza di un problema non e' ovvio. Infatti dobbiamo dimostrare che tutti i
problemi in $\NPClass$ sono riducibili al problema che vogliamo dimostrare essere completo.

Il problema che consideriamo e' il problema limitato della fermata con macchine non deterministiche.

\begin{thm}
    Sia $\BHP$ il linguaggio cosi' definito:
    \begin{equation*}
        \BHP = \set {\tuple{x,y,0^{t}} \mid \text{La MdTN $M$ accetta $y$ in tempo
        $\textit{time}_{M_{x}}(y) \leq t$}}
    \end{equation*}
    $\BHP$ e' $\NPClass$-completo
\end{thm}

Il tempo e' dato in formato unario. Di solito si fa cosi' quando vogliamo una complessita' lineare
in un dato tempo.  Se dessimo una rappresentazione logaritmica del tempo l'algoritmo che lavora con
quel tempo risulterebbe avere complessita' esponenziale.

\begin{proof}
    La prima cosa da fare e' dimostrare che questo problema sta in $\NPClass$. Costruiamo una MdTN
    $M$ che riconosce $\BHP$. $M$ opera nel seguente modo: verifica innanzitutto che la stringa in
    input sia una tripla la cui prima componente sia il codice di una MdTN. Dopodiche' simula la
    computazione della macchina $M_{x}$ su input $y$ con bound dato da $t$. Ad ogni scelta non
    deterministica di $M_{x}$ corrisponde una scelta non deterministica di $M$. Se alla fine della
    simulazione abbiamo che $M_{x}$ riconosce $y$ abbiamo che $M$ accetta, altrimenti rifiuta.
    Rifiuta inoltre se la simulazione supera il bound in tempo. 
    
    Supponiamo ora di avere un linguaggio $A \in \NPClass$ e di volerlo riconoscere, ovvero decidere
    $y \in A$.  Possiamo farlo con una riduzione polinomiale a $\BHP$: prendiamo il codice $x$ di
    una MdTN $M$ che riconosce $A$ in tempo polinomiale, l'input $y$ da riconoscere e come tempo $t$
    prendiamo $p(|y|)$, dove $p$ e' il polinomio che fa da bound alla complessita' di $M$. Abbiamo
    che $y \in A \iff \tuple{x,y,0^{t}} \in \BHP$.
\end{proof}

$\BHP$ non e' stato molto investigato. Dal punto di vista pratico non e' il miglior problema a cui
ridursi. La costruzione di $\BHP$ inoltre e' un po' artificiosa, serve giusto a dimostare che
esistono problemi $\NPClass$-completi.

Si poteva dimostrare inoltre che $\BHP \in \NPClass$ mostrando un certificato per esso ed un
algoritmo efficiente di verifica. In questo caso un certicato poteva essere la sequenza delle
decisioni prese dalla macchina $M_{x}$ su input $y$ e la verifica sarebbe consistita nella
simulazione di $M_{x}$ su input $y$ seguendo la sequenza di istruzioni data dal certificato.
